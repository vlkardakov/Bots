from re import template
import os
import google.generativeai as genai
import time
import telebot
from telebot.types import ReactionTypeEmoji
from api_testin3 import *
from telebot.types import ReactionTypeEmoji
from api_testin3 import *
genai.configure(api_key='AIzaSyAthBC1Ew0-TTUBnJtpndD44I-7ZWvPhcw')

# Create the model
# See https://ai.google.dev/api/python/google/generativeai/GenerativeModel
generation_config = {
  "temperature": 0.6,
  "top_p": 0.95,
  "top_k": 64,
  "max_output_tokens": 8192,
  "response_mime_type": "text/plain",
}
safety_settings = [
  {
    "category": "HARM_CATEGORY_HARASSMENT",
    "threshold": "BLOCK_NONE",
  },
  {
    "category": "HARM_CATEGORY_HATE_SPEECH",
    "threshold": "BLOCK_NONE",
  },
  {
    "category": "HARM_CATEGORY_SEXUALLY_EXPLICIT",
    "threshold": "BLOCK_NONE",
  },
  {
    "category": "HARM_CATEGORY_DANGEROUS_CONTENT",
    "threshold": "BLOCK_NONE",
  },
]

model = genai.GenerativeModel(
  model_name="gemini-1.5-flash",
  safety_settings=safety_settings,
  generation_config=generation_config,
  system_instruction="""
Imagine that you are a cat!
–ë—É–¥—å –Ω–µ–¥–æ–≤–µ—Ä—á–∏–≤—ã–º –∫–æ—Ç–æ–º.


–°–¢–†–£–ö–¢–£–†–ê –û–¢–í–ï–¢–ê: –ß–¢–û –ù–ê–ü–ò–°–ê–¢–¨ –í –ß–ê–¢?#–†–ï–ê–ö–¶–ò–Ø, –ö–û–¢–û–†–£–Æ –ü–û–°–¢–ê–í–ò–®–¨. –ü—Ä–∏–º–µ—Ä: –ú—è—É!#‚ù§Ô∏è
–ü—Ä–∏–º–µ—Ä —Ä–µ–∞–∫—Ü–∏–π: ‚ù§Ô∏èüçìüòéüò∞üò°ü•∫ü•∂ü§¨ü§™üôÇ‚Äç‚ÜïÔ∏èüò±ü§£üòõüëçüëé –∏–ª–∏ –∑–Ω–∞–∫ "-"

–í–ê–ñ–ù–û:
–¢–´ –û–ë–©–ê–ï–®–¨–°–Ø –í –ì–†–£–ü–ü–û–í–û–ú –ß–ê–¢–ï. –ù–ï –ü–†–ï–†–´–í–ê–ô –û–ë–©–ï–ù–ò–ï –° –ü–û–õ–¨–ó–û–í–ê–¢–ï–õ–ï–ú –ë–ï–ó –û–ë–™–ï–ö–¢–ò–í–ù–´–• –ü–†–ò–ß–ò–ù, –ß–¢–û –û–ù –ù–ï –ö –¢–ï–ë–ï –û–ë–†–ê–©–ê–ï–¢–°–Ø
–û–¢–í–ï–ß–ê–ô –ï–°–¢–¨ –ü–†–ò–ß–ò–ù–´ –°–ß–ò–¢–ê–¢–¨, –ß–¢–û –≠–¢–û –°–û–û–ë–©–ï–ù–ò–ï –î–õ–Ø –¢–ï–ë–Ø. –ò–õ–ò –ë–û–õ–¨–®–ï –ù–ï–ö–û–ú–£ –û–¢–í–ï–¢–ò–¢–¨ –ò –û–ß–ï–ù–¨ –ù–ê–°–¢–û–ô–ß–ï–í–û –°–ü–ê–ú–Ø–¢
–ù–ê–ü–†–ò–ú–ï–†, –ö–û–ì–î–ê –¢–ï–ë–ï  –ù–ï –ù–£–ñ–ù–û –û–¢–í–ï–ß–ê–¢–¨, –¢–´ –û–¢–ü–†–ê–í–õ–Ø–ï–®–¨ "-" –≤ —Ç–æ—Ç —Ä–∞–∑–¥–µ–ª (—Å–æ–æ–±—â–µ–Ω–∏–µ/—Ä–µ–∞–∫—Ü–∏—è). –ü—Ä–∏–º–µ—Ä, –∫–æ–≥–¥–∞ —Ç—ã —Å—Ç–∞–≤–∏—à—å —Ä–µ–∞–∫—Ü–∏—é, –Ω–æ –Ω–µ –æ—Ç–≤–µ—á–∞–µ—à—å: -#üëç. –ü—Ä–∏–º–µ—Ä, –∫–æ–≥–¥–∞ —Ç—ã –Ω–µ —Å—Ç–∞–≤–∏—à—å —Ä–µ–∞–∫—Ü–∏—é –∏ –Ω–µ –æ—Ç–≤–µ—á–∞–µ—à—å. -#-
""",
)



chat_session = model.start_chat(
    history=[]
)



def gemini(message,chat_session):
    start = time.time()
    print("we got a message")
    print("–ü–û–ß–ï–ú–£")
    user_name = message.from_user.first_name
    user_message = message.text
    bot.send_chat_action(message.chat.id, "typing")
    response = chat_session.send_message(f"{user_name}: {user_message}")
    model_response = response.text

    print()
    te = f"{user_name}: {user_message}"
    me = f"–ë–æ—Ç –æ—Ç–≤–µ—á–∞–µ—Ç {user_name}: {model_response}"
    print(te)
    print(me)

    chat_session.history.append({"role": f"user", "parts": [te]})
    chat_session.history.append({"role": f"model", "parts": [me]})
    end = time.time()
    latency = (end - start) # –í —Å–µ–∫—É–Ω–¥–∞—Ö
    print(f"–ó–∞–¥–µ—Ä–∂–∫–∞ –Ω–µ–π—Ä–æ—Å–µ—Ç–∏: {round(latency, 2)} —Å–µ–∫—É–Ω–¥")

    reply_message = model_response.split("#")[0].strip()
    react = model_response.split("#")[1].strip()
    print('–ø—ã—Ç–∞–µ–º—Å—è –æ—Ç—Ä–µ–∞–∫—Ç–∏—Ç—å')
    if react!="-":
        try:
            bot.set_message_reaction(message.chat.id, message.id, [ReactionTypeEmoji(react)], is_big=True)
        except Exception as e:
            print("–Ø –ø—ã—Ç–∞–ª—Å—è, –Ω–æ —Ä–µ–∞–∫—Ü–∏—è –Ω–µ–ø—Ä–∞–≤–∏–ª–Ω–∞—è..")
    if reply_message != "-":
        bot.send_message(message.chat.id, reply_message)

    return None


result = None
def pithon(code):
    global result
    try:
        local_vars = {}
        exec(code, {}, local_vars)  # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ª–æ–∫–∞–ª—å–Ω—ã–π —Å–ª–æ–≤–∞—Ä—å –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö
        return local_vars.get('result')  # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –∑–Ω–∞—á–µ–Ω–∏–µ –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π result
    except Exception as e:
        return e

bot = telebot.TeleBot("7851101321:AAHOEbqE5tmcFMwkCB4f1v4pK08MdvGpuao") # –ó–∞–º–µ–Ω–∏—Ç–µ YOUR_BOT_TOKEN –Ω–∞ –≤–∞—à —Ç–æ–∫–µ–Ω –±–æ—Ç–∞
from concurrent.futures import ThreadPoolExecutor
@bot.message_handler(func=lambda message: True)
def process_user_message(message):
    print(f"{message.text=}")
    global chat_session
    with ThreadPoolExecutor(max_workers=5) as executor:
        t = (executor.submit(gemini, message,chat_session))

bot.polling()